{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of dataset collected: 28\n",
      "No limit set for data collection except skip random no of files up to 5\n",
      "Training shape:  (5408, 3840, 64) (5408, 3840, 64)\n",
      "Validation shape:  (896, 3840, 64) (896, 3840, 64)\n",
      "Test shape:  (2278, 3840, 64) (2278, 3840, 64)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "train1 = \"Data/readelf/train_dataset1.npz\"\n",
    "train2 = \"Data/readelf/train_dataset2.npz\"\n",
    "val = \"Data/readelf/val_dataset.npz\"\n",
    "test = \"Data/readelf/test_dataset.npz\"\n",
    "\n",
    "# Load numpy array\n",
    "training_dataset1 = np.load(train1)\n",
    "training_dataset2 = np.load(train2)\n",
    "val_dataset = np.load(val)\n",
    "test_dataset = np.load(test)\n",
    "\n",
    "x_train = np.concatenate((training_dataset1['x'], training_dataset2['x']))[:5408]\n",
    "y_train = np.concatenate((training_dataset1['y'], training_dataset2['y']))[:5408]\n",
    "\n",
    "# Swap val and test\n",
    "x_test = val_dataset['x']\n",
    "y_test = val_dataset['y']\n",
    "\n",
    "x_val = test_dataset['x'][:896]\n",
    "y_val = test_dataset['y'][:896]\n",
    "\n",
    "print(\"No. of dataset collected: 28\")\n",
    "print(\"No limit set for data collection except skip random no of files up to 5\")\n",
    "print(\"Training shape: \", x_train.shape, y_train.shape)\n",
    "print(\"Validation shape: \", x_val.shape, x_val.shape)\n",
    "print(\"Test shape: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 3840, 64)          33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3840, 64)          4160      \n",
      "=================================================================\n",
      "Total params: 37,184\n",
      "Trainable params: 37,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5408 samples, validate on 896 samples\n",
      "Epoch 1/50\n",
      "5408/5408 [==============================] - 1000s 185ms/step - loss: 0.4871 - mean_absolute_error: 0.4871 - mean_squared_error: 0.2394 - val_loss: 0.4644 - val_mean_absolute_error: 0.4644 - val_mean_squared_error: 0.2206\n",
      "Epoch 2/50\n",
      "5408/5408 [==============================] - 928s 172ms/step - loss: 0.3241 - mean_absolute_error: 0.3241 - mean_squared_error: 0.1233 - val_loss: 0.2202 - val_mean_absolute_error: 0.2202 - val_mean_squared_error: 0.0629\n",
      "Epoch 3/50\n",
      "5408/5408 [==============================] - 921s 170ms/step - loss: 0.1626 - mean_absolute_error: 0.1626 - mean_squared_error: 0.0425 - val_loss: 0.1148 - val_mean_absolute_error: 0.1148 - val_mean_squared_error: 0.0266\n",
      "Epoch 4/50\n",
      "5408/5408 [==============================] - 915s 169ms/step - loss: 0.0926 - mean_absolute_error: 0.0926 - mean_squared_error: 0.0236 - val_loss: 0.0740 - val_mean_absolute_error: 0.0740 - val_mean_squared_error: 0.0187\n",
      "Epoch 5/50\n",
      "5408/5408 [==============================] - 902s 167ms/step - loss: 0.0664 - mean_absolute_error: 0.0664 - mean_squared_error: 0.0196 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566 - val_mean_squared_error: 0.0168\n",
      "Epoch 6/50\n",
      "5408/5408 [==============================] - 896s 166ms/step - loss: 0.0532 - mean_absolute_error: 0.0532 - mean_squared_error: 0.0185 - val_loss: 0.0465 - val_mean_absolute_error: 0.0465 - val_mean_squared_error: 0.0161\n",
      "Epoch 7/50\n",
      "5408/5408 [==============================] - 897s 166ms/step - loss: 0.0453 - mean_absolute_error: 0.0453 - mean_squared_error: 0.0181 - val_loss: 0.0401 - val_mean_absolute_error: 0.0401 - val_mean_squared_error: 0.0158\n",
      "Epoch 8/50\n",
      "5408/5408 [==============================] - 881s 163ms/step - loss: 0.0399 - mean_absolute_error: 0.0399 - mean_squared_error: 0.0179 - val_loss: 0.0355 - val_mean_absolute_error: 0.0355 - val_mean_squared_error: 0.0156\n",
      "Epoch 9/50\n",
      "5408/5408 [==============================] - 884s 163ms/step - loss: 0.0359 - mean_absolute_error: 0.0359 - mean_squared_error: 0.0178 - val_loss: 0.0321 - val_mean_absolute_error: 0.0321 - val_mean_squared_error: 0.0156\n",
      "Epoch 10/50\n",
      "5408/5408 [==============================] - 895s 166ms/step - loss: 0.0329 - mean_absolute_error: 0.0329 - mean_squared_error: 0.0178 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295 - val_mean_squared_error: 0.0156\n",
      "Epoch 11/50\n",
      "5408/5408 [==============================] - 920s 170ms/step - loss: 0.0306 - mean_absolute_error: 0.0306 - mean_squared_error: 0.0178 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274 - val_mean_squared_error: 0.0155\n",
      "Epoch 12/50\n",
      "5408/5408 [==============================] - 934s 173ms/step - loss: 0.0288 - mean_absolute_error: 0.0288 - mean_squared_error: 0.0178 - val_loss: 0.0258 - val_mean_absolute_error: 0.0258 - val_mean_squared_error: 0.0155\n",
      "Epoch 13/50\n",
      "5408/5408 [==============================] - 939s 174ms/step - loss: 0.0273 - mean_absolute_error: 0.0273 - mean_squared_error: 0.0178 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244 - val_mean_squared_error: 0.0156\n",
      "Epoch 14/50\n",
      "5408/5408 [==============================] - 934s 173ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - mean_squared_error: 0.0178 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233 - val_mean_squared_error: 0.0156\n",
      "Epoch 15/50\n",
      "5408/5408 [==============================] - 932s 172ms/step - loss: 0.0251 - mean_absolute_error: 0.0251 - mean_squared_error: 0.0178 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224 - val_mean_squared_error: 0.0156\n",
      "Epoch 16/50\n",
      "5408/5408 [==============================] - 942s 174ms/step - loss: 0.0242 - mean_absolute_error: 0.0242 - mean_squared_error: 0.0178 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216 - val_mean_squared_error: 0.0156\n",
      "Epoch 17/50\n",
      "5408/5408 [==============================] - 937s 173ms/step - loss: 0.0235 - mean_absolute_error: 0.0235 - mean_squared_error: 0.0178 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209 - val_mean_squared_error: 0.0156\n",
      "Epoch 18/50\n",
      "5408/5408 [==============================] - 938s 173ms/step - loss: 0.0229 - mean_absolute_error: 0.0229 - mean_squared_error: 0.0178 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203 - val_mean_squared_error: 0.0156\n",
      "Epoch 19/50\n",
      "5408/5408 [==============================] - 875s 162ms/step - loss: 0.0223 - mean_absolute_error: 0.0223 - mean_squared_error: 0.0178 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198 - val_mean_squared_error: 0.0156\n",
      "Epoch 20/50\n",
      "5408/5408 [==============================] - 880s 163ms/step - loss: 0.0219 - mean_absolute_error: 0.0219 - mean_squared_error: 0.0179 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194 - val_mean_squared_error: 0.0156\n",
      "Epoch 21/50\n",
      "5408/5408 [==============================] - 900s 166ms/step - loss: 0.0215 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0179 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190 - val_mean_squared_error: 0.0156\n",
      "Epoch 22/50\n",
      "5408/5408 [==============================] - 900s 166ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - mean_squared_error: 0.0179 - val_loss: 0.0187 - val_mean_absolute_error: 0.0187 - val_mean_squared_error: 0.0156\n",
      "Epoch 23/50\n",
      "5408/5408 [==============================] - 897s 166ms/step - loss: 0.0208 - mean_absolute_error: 0.0208 - mean_squared_error: 0.0179 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184 - val_mean_squared_error: 0.0156\n",
      "Epoch 24/50\n",
      "5408/5408 [==============================] - 890s 165ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - mean_squared_error: 0.0179 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181 - val_mean_squared_error: 0.0156\n",
      "Epoch 25/50\n",
      "5408/5408 [==============================] - 895s 166ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0179 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179 - val_mean_squared_error: 0.0156\n",
      "Epoch 26/50\n",
      "5408/5408 [==============================] - 902s 167ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - mean_squared_error: 0.0179 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177 - val_mean_squared_error: 0.0156\n",
      "Epoch 27/50\n",
      "5408/5408 [==============================] - 887s 164ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0179 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175 - val_mean_squared_error: 0.0156\n",
      "Epoch 28/50\n",
      "5408/5408 [==============================] - 866s 160ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0179 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173 - val_mean_squared_error: 0.0156\n",
      "Epoch 29/50\n",
      "5408/5408 [==============================] - 888s 164ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0179 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172 - val_mean_squared_error: 0.0157\n",
      "Epoch 30/50\n",
      "5408/5408 [==============================] - 917s 170ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - mean_squared_error: 0.0179 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171 - val_mean_squared_error: 0.0157\n",
      "Epoch 31/50\n",
      "5408/5408 [==============================] - 910s 168ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0179 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169 - val_mean_squared_error: 0.0157\n",
      "Epoch 32/50\n",
      "5408/5408 [==============================] - 902s 167ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0179 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168 - val_mean_squared_error: 0.0157\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5408/5408 [==============================] - 918s 170ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0179 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167 - val_mean_squared_error: 0.0157\n",
      "Epoch 34/50\n",
      "5408/5408 [==============================] - 899s 166ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0179 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166 - val_mean_squared_error: 0.0157\n",
      "Epoch 35/50\n",
      "5408/5408 [==============================] - 905s 167ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - mean_squared_error: 0.0179 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166 - val_mean_squared_error: 0.0157\n",
      "Epoch 36/50\n",
      "5408/5408 [==============================] - 881s 163ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - mean_squared_error: 0.0179 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165 - val_mean_squared_error: 0.0157\n",
      "Epoch 37/50\n",
      "5408/5408 [==============================] - 867s 160ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - mean_squared_error: 0.0179 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164 - val_mean_squared_error: 0.0157\n",
      "Epoch 38/50\n",
      "5408/5408 [==============================] - 892s 165ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - mean_squared_error: 0.0179 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164 - val_mean_squared_error: 0.0157\n",
      "Epoch 39/50\n",
      "5408/5408 [==============================] - 886s 164ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - mean_squared_error: 0.0179 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163 - val_mean_squared_error: 0.0157\n",
      "Epoch 40/50\n",
      "5408/5408 [==============================] - 909s 168ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - mean_squared_error: 0.0179 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162 - val_mean_squared_error: 0.0157\n",
      "Epoch 41/50\n",
      "5408/5408 [==============================] - 898s 166ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - mean_squared_error: 0.0179 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162 - val_mean_squared_error: 0.0157\n",
      "Epoch 42/50\n",
      "5408/5408 [==============================] - 904s 167ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - mean_squared_error: 0.0179 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162 - val_mean_squared_error: 0.0157\n",
      "Epoch 43/50\n",
      "5408/5408 [==============================] - 907s 168ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - mean_squared_error: 0.0179 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161 - val_mean_squared_error: 0.0157\n",
      "Epoch 44/50\n",
      "5408/5408 [==============================] - 896s 166ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - mean_squared_error: 0.0179 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161 - val_mean_squared_error: 0.0157\n",
      "Epoch 45/50\n",
      "5408/5408 [==============================] - 903s 167ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - mean_squared_error: 0.0179 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161 - val_mean_squared_error: 0.0157\n",
      "Epoch 46/50\n",
      "5408/5408 [==============================] - 905s 167ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - mean_squared_error: 0.0179 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160 - val_mean_squared_error: 0.0157\n",
      "Epoch 47/50\n",
      "5408/5408 [==============================] - 899s 166ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - mean_squared_error: 0.0179 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160 - val_mean_squared_error: 0.0157\n",
      "Epoch 48/50\n",
      "5408/5408 [==============================] - 891s 165ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - mean_squared_error: 0.0180 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160 - val_mean_squared_error: 0.0157\n",
      "Epoch 49/50\n",
      "5408/5408 [==============================] - 897s 166ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - mean_squared_error: 0.0180 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159 - val_mean_squared_error: 0.0157\n",
      "Epoch 50/50\n",
      "5408/5408 [==============================] - 907s 168ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - mean_squared_error: 0.0180 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159 - val_mean_squared_error: 0.0157\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(3840, 64), return_sequences=True))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.summary()\n",
    "adam = Adam(lr=0.00005)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_error', metrics=['mae', 'mse'])\n",
    "\n",
    "# Fitting the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7c374c90f0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f1374fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# plot metrics\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 82s 36ms/step\n",
      "Test loss: [0.019452046196124024, 0.019452047376196196, 0.01920869672796153]\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "[0.02259866 0.02244423 0.02446855 0.01174372 0.02425988 0.02601697\n",
      " 0.03018723 0.02878637 0.02434062 0.0290934  0.02256729 0.01727344\n",
      " 0.0149908  0.02444302 0.0204846  0.04039619 0.02539571 0.02832797\n",
      " 0.02906331 0.02661638 0.01932438 0.03491028 0.02750013 0.02091917\n",
      " 0.02481431 0.01903054 0.02821853 0.0319971  0.01492403 0.01564083\n",
      " 0.02510514 0.02349243 0.03090925 0.02267551 0.02414665 0.02364828\n",
      " 0.02495493 0.0290453  0.01565789 0.01501844 0.03241829 0.01559309\n",
      " 0.02353551 0.01657164 0.01951363 0.02536671 0.02615028 0.02373122\n",
      " 0.02664093 0.01824579 0.02367322 0.02514883 0.02450225 0.02833408\n",
      " 0.02788492 0.01823691 0.02758023 0.03011452 0.02539704 0.02094792\n",
      " 0.02807122 0.0180523  0.0243539  0.02070882]\n",
      "[0.00951941 0.00777281 0.01089209 0.00490356 0.01049751 0.01216136\n",
      " 0.01310169 0.01222849 0.01018134 0.009613   0.01120137 0.00718602\n",
      " 0.00533361 0.01022918 0.00764832 0.0142453  0.01041134 0.01081686\n",
      " 0.00920606 0.00979189 0.00802181 0.01374868 0.01249845 0.00876599\n",
      " 0.01019493 0.00864797 0.01045883 0.01025961 0.00647306 0.0056993\n",
      " 0.01081749 0.01050164 0.01224538 0.00879272 0.00852303 0.01060442\n",
      " 0.0102524  0.01106978 0.00590752 0.006566   0.01313141 0.00717736\n",
      " 0.00936668 0.00650021 0.00804328 0.01086957 0.01086176 0.00929484\n",
      " 0.01075369 0.00711298 0.01128719 0.01265769 0.00940109 0.01354521\n",
      " 0.00862831 0.00837971 0.01004542 0.01124019 0.01030553 0.01011416\n",
      " 0.01107175 0.0064459  0.01248714 0.00943424]\n",
      "[0.00149732 0.00119192 0.0018571  0.00057421 0.00172872 0.00212923\n",
      " 0.00248441 0.002187   0.00153582 0.00159511 0.00184628 0.00101133\n",
      " 0.00067095 0.00171124 0.0011812  0.00254616 0.00163977 0.00198407\n",
      " 0.00142253 0.00148963 0.0012426  0.00234128 0.00223682 0.00132252\n",
      " 0.0016048  0.00141266 0.0017632  0.0016059  0.00087115 0.00070249\n",
      " 0.00166802 0.00194341 0.00190806 0.00133351 0.00138252 0.00176208\n",
      " 0.00161296 0.00178271 0.00082513 0.00102516 0.00232287 0.00098063\n",
      " 0.00153637 0.00085268 0.00108752 0.0017268  0.00172048 0.00129545\n",
      " 0.00176746 0.00105592 0.00198659 0.00227021 0.00133792 0.00247797\n",
      " 0.00124001 0.00137369 0.0016805  0.00175966 0.00164728 0.00159789\n",
      " 0.00191701 0.0009189  0.00199818 0.0013112 ]\n",
      "[0.00036677 0.00028502 0.00056222 0.00011108 0.00045125 0.0005398\n",
      " 0.0006845  0.00051713 0.00038088 0.00035898 0.00045558 0.00023701\n",
      " 0.0001391  0.00039109 0.00029012 0.00062147 0.00041119 0.00054135\n",
      " 0.00033903 0.00036767 0.00024921 0.000663   0.00065118 0.00033023\n",
      " 0.00041573 0.00035203 0.00043333 0.00038699 0.00019474 0.00014432\n",
      " 0.00042726 0.00045675 0.00047794 0.0003092  0.00033619 0.00047831\n",
      " 0.0004357  0.00045699 0.00017574 0.00025258 0.00064393 0.00024927\n",
      " 0.00038078 0.00019406 0.00024326 0.00041104 0.00046554 0.00032728\n",
      " 0.00045486 0.00022167 0.00054603 0.00068461 0.00033684 0.00076608\n",
      " 0.00030304 0.00032815 0.00040193 0.00043486 0.00045971 0.00043646\n",
      " 0.00044098 0.00020906 0.00059886 0.0003137 ]\n",
      "[2.4654882e-04 1.9009116e-04 3.8071061e-04 7.2469913e-05 3.1820335e-04\n",
      " 3.9760713e-04 4.6995701e-04 3.5030517e-04 2.5072214e-04 2.2349838e-04\n",
      " 3.0633097e-04 1.6112567e-04 8.7739456e-05 2.5241743e-04 1.9089451e-04\n",
      " 4.1032073e-04 2.6997551e-04 3.6075679e-04 2.1417408e-04 2.3879294e-04\n",
      " 1.6577396e-04 4.4463715e-04 4.4930089e-04 2.2927334e-04 2.6997676e-04\n",
      " 2.4634579e-04 2.9394231e-04 2.3769014e-04 1.3152702e-04 9.0701833e-05\n",
      " 2.9023751e-04 3.1283050e-04 3.0914310e-04 2.0547990e-04 2.1467578e-04\n",
      " 3.2143469e-04 2.9324644e-04 2.9612335e-04 1.2153551e-04 1.7121836e-04\n",
      " 4.3401710e-04 1.6448679e-04 2.4635310e-04 1.2911923e-04 1.6008844e-04\n",
      " 2.7165533e-04 3.0781026e-04 2.0456190e-04 3.0204674e-04 1.4383324e-04\n",
      " 3.8682012e-04 4.8168236e-04 2.0825726e-04 5.3569319e-04 1.8621777e-04\n",
      " 2.2955704e-04 2.5901620e-04 2.7643188e-04 3.0202026e-04 2.9386693e-04\n",
      " 3.0260073e-04 1.3745435e-04 4.1231950e-04 2.1389061e-04]\n",
      "[0.02259866 0.02244423 0.02446855 0.01174372 0.02425988 0.02601697\n",
      " 0.03018723 0.02878637 0.02434062 0.0290934  0.02256729 0.01727344\n",
      " 0.0149908  0.02444302 0.0204846  0.04039619 0.02539571 0.02832797\n",
      " 0.02906331 0.02661638 0.01932438 0.03491028 0.02750013 0.02091917\n",
      " 0.02481431 0.01903054 0.02821853 0.0319971  0.01492403 0.01564083\n",
      " 0.02510514 0.02349243 0.03090925 0.02267551 0.02414665 0.02364828\n",
      " 0.02495493 0.0290453  0.01565789 0.01501844 0.03241829 0.01559309\n",
      " 0.02353551 0.01657164 0.01951363 0.02536671 0.02615028 0.02373122\n",
      " 0.02664093 0.01824579 0.02367322 0.02514883 0.02450225 0.02833408\n",
      " 0.02788492 0.01823691 0.02758023 0.03011452 0.02539704 0.02094792\n",
      " 0.02807122 0.0180523  0.0243539  0.02070882]\n",
      "[0.00951941 0.00777281 0.01089209 0.00490356 0.01049751 0.01216136\n",
      " 0.01310169 0.01222849 0.01018134 0.009613   0.01120137 0.00718602\n",
      " 0.00533361 0.01022918 0.00764832 0.0142453  0.01041134 0.01081686\n",
      " 0.00920606 0.00979189 0.00802181 0.01374868 0.01249845 0.00876599\n",
      " 0.01019493 0.00864797 0.01045883 0.01025961 0.00647306 0.0056993\n",
      " 0.01081749 0.01050164 0.01224538 0.00879272 0.00852303 0.01060442\n",
      " 0.0102524  0.01106978 0.00590752 0.006566   0.01313141 0.00717736\n",
      " 0.00936668 0.00650021 0.00804328 0.01086957 0.01086176 0.00929484\n",
      " 0.01075369 0.00711298 0.01128719 0.01265769 0.00940109 0.01354521\n",
      " 0.00862831 0.00837971 0.01004542 0.01124019 0.01030553 0.01011416\n",
      " 0.01107175 0.0064459  0.01248714 0.00943424]\n",
      "[0.00149732 0.00119192 0.0018571  0.00057421 0.00172872 0.00212923\n",
      " 0.00248441 0.002187   0.00153582 0.00159511 0.00184628 0.00101133\n",
      " 0.00067095 0.00171124 0.0011812  0.00254616 0.00163977 0.00198407\n",
      " 0.00142253 0.00148963 0.0012426  0.00234128 0.00223682 0.00132252\n",
      " 0.0016048  0.00141266 0.0017632  0.0016059  0.00087115 0.00070249\n",
      " 0.00166802 0.00194341 0.00190806 0.00133351 0.00138252 0.00176208\n",
      " 0.00161296 0.00178271 0.00082513 0.00102516 0.00232287 0.00098063\n",
      " 0.00153637 0.00085268 0.00108752 0.0017268  0.00172048 0.00129545\n",
      " 0.00176746 0.00105592 0.00198659 0.00227021 0.00133792 0.00247797\n",
      " 0.00124001 0.00137369 0.0016805  0.00175966 0.00164728 0.00159789\n",
      " 0.00191701 0.0009189  0.00199818 0.0013112 ]\n",
      "[0.00036677 0.00028502 0.00056222 0.00011108 0.00045125 0.0005398\n",
      " 0.0006845  0.00051713 0.00038088 0.00035898 0.00045558 0.00023701\n",
      " 0.0001391  0.00039109 0.00029012 0.00062147 0.00041119 0.00054135\n",
      " 0.00033903 0.00036767 0.00024921 0.000663   0.00065118 0.00033023\n",
      " 0.00041573 0.00035203 0.00043333 0.00038699 0.00019474 0.00014432\n",
      " 0.00042726 0.00045675 0.00047794 0.0003092  0.00033619 0.00047831\n",
      " 0.0004357  0.00045699 0.00017574 0.00025258 0.00064393 0.00024927\n",
      " 0.00038078 0.00019406 0.00024326 0.00041104 0.00046554 0.00032728\n",
      " 0.00045486 0.00022167 0.00054603 0.00068461 0.00033684 0.00076608\n",
      " 0.00030304 0.00032815 0.00040193 0.00043486 0.00045971 0.00043646\n",
      " 0.00044098 0.00020906 0.00059886 0.0003137 ]\n",
      "[2.4654882e-04 1.9009116e-04 3.8071061e-04 7.2469913e-05 3.1820335e-04\n",
      " 3.9760713e-04 4.6995701e-04 3.5030517e-04 2.5072214e-04 2.2349838e-04\n",
      " 3.0633097e-04 1.6112567e-04 8.7739456e-05 2.5241743e-04 1.9089451e-04\n",
      " 4.1032073e-04 2.6997551e-04 3.6075679e-04 2.1417408e-04 2.3879294e-04\n",
      " 1.6577396e-04 4.4463715e-04 4.4930089e-04 2.2927334e-04 2.6997676e-04\n",
      " 2.4634579e-04 2.9394231e-04 2.3769014e-04 1.3152702e-04 9.0701833e-05\n",
      " 2.9023751e-04 3.1283050e-04 3.0914310e-04 2.0547990e-04 2.1467578e-04\n",
      " 3.2143469e-04 2.9324644e-04 2.9612335e-04 1.2153551e-04 1.7121836e-04\n",
      " 4.3401710e-04 1.6448679e-04 2.4635310e-04 1.2911923e-04 1.6008844e-04\n",
      " 2.7165533e-04 3.0781026e-04 2.0456190e-04 3.0204674e-04 1.4383324e-04\n",
      " 3.8682012e-04 4.8168236e-04 2.0825726e-04 5.3569319e-04 1.8621777e-04\n",
      " 2.2955704e-04 2.5901620e-04 2.7643188e-04 3.0202026e-04 2.9386693e-04\n",
      " 3.0260073e-04 1.3745435e-04 4.1231950e-04 2.1389061e-04]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(np.argmax(predictions[0][0]))\n",
    "print(predictions[0][0])\n",
    "print(predictions[0][1])\n",
    "print(predictions[0][2])\n",
    "print(predictions[0][3])\n",
    "print(predictions[0][4])\n",
    "print(predictions[1][0])\n",
    "print(predictions[1][1])\n",
    "print(predictions[1][2])\n",
    "print(predictions[1][3])\n",
    "print(predictions[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
