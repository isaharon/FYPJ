{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (2560, 1280, 64) (2560, 1280, 64)\n",
      "Validation shape:  (640, 1280, 64) (640, 1280, 64)\n",
      "Test shape:  (800, 1280, 64) (800, 1280, 64)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "filename = \"Data/XML/xml_dataset.npz\"\n",
    "\n",
    "# Load numpy array\n",
    "dataset = np.load(filename)\n",
    "\n",
    "x_dataset_full = dataset['x']\n",
    "y_dataset_full = dataset['y']\n",
    "\n",
    "x_test = x_dataset_full[3200:4000]\n",
    "y_test = y_dataset_full[3200:4000]\n",
    "\n",
    "x_dataset = x_dataset_full[:3200]\n",
    "y_dataset = y_dataset_full[:3200]\n",
    "\n",
    "x_val = x_dataset[2560:]\n",
    "y_val = y_dataset[2560:]\n",
    "\n",
    "x_train = x_dataset[:2560]\n",
    "y_train = y_dataset[:2560]\n",
    "\n",
    "# Assign and reshape data\n",
    "x_train, y_train = x_train.reshape(2560, 1280, 64), y_train.reshape(2560, 1280, 64)\n",
    "x_val, y_val = x_val.reshape(640, 1280, 64), y_val.reshape(640, 1280, 64)\n",
    "x_test, y_test = x_test.reshape(800, 1280, 64), y_test.reshape(800, 1280, 64)\n",
    "\n",
    "print(\"Training shape: \", x_train.shape, y_train.shape)\n",
    "print(\"Validation shape: \", x_val.shape, x_val.shape)\n",
    "print(\"Test shape: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1280, 64)          33024     \n",
      "=================================================================\n",
      "Total params: 33,024\n",
      "Trainable params: 33,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2560 samples, validate on 640 samples\n",
      "Epoch 1/400\n",
      "2560/2560 [==============================] - 93s 36ms/step - loss: 0.0363 - acc: 0.0199 - val_loss: 0.0117 - val_acc: 0.0014\n",
      "Epoch 2/400\n",
      "2560/2560 [==============================] - 85s 33ms/step - loss: 0.0338 - acc: 0.0547 - val_loss: 0.0108 - val_acc: 0.0012\n",
      "Epoch 3/400\n",
      "2560/2560 [==============================] - 84s 33ms/step - loss: 0.0322 - acc: 0.0027 - val_loss: 0.0102 - val_acc: 0.0012\n",
      "Epoch 4/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0310 - acc: 0.0267 - val_loss: 0.0098 - val_acc: 8.8745e-04\n",
      "Epoch 5/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0301 - acc: 0.0038 - val_loss: 0.0094 - val_acc: 8.4351e-04\n",
      "Epoch 6/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0294 - acc: 0.0026 - val_loss: 0.0092 - val_acc: 7.8125e-04\n",
      "Epoch 7/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0289 - acc: 0.0025 - val_loss: 0.0090 - val_acc: 6.6284e-04\n",
      "Epoch 8/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0284 - acc: 0.0023 - val_loss: 0.0088 - val_acc: 6.3110e-04\n",
      "Epoch 9/400\n",
      "2560/2560 [==============================] - 88s 34ms/step - loss: 0.0281 - acc: 0.0236 - val_loss: 0.0087 - val_acc: 8.9355e-04\n",
      "Epoch 10/400\n",
      "2560/2560 [==============================] - 85s 33ms/step - loss: 0.0278 - acc: 0.0017 - val_loss: 0.0086 - val_acc: 7.3242e-04\n",
      "Epoch 11/400\n",
      "2560/2560 [==============================] - 88s 34ms/step - loss: 0.0275 - acc: 0.0199 - val_loss: 0.0085 - val_acc: 6.4453e-04\n",
      "Epoch 12/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0273 - acc: 0.0232 - val_loss: 0.0084 - val_acc: 7.0557e-04\n",
      "Epoch 13/400\n",
      "2560/2560 [==============================] - 87s 34ms/step - loss: 0.0272 - acc: 0.0497 - val_loss: 0.0084 - val_acc: 7.1411e-04\n",
      "Epoch 14/400\n",
      "2560/2560 [==============================] - 86s 34ms/step - loss: 0.0270 - acc: 0.0015 - val_loss: 0.0083 - val_acc: 6.7139e-04\n",
      "Epoch 15/400\n",
      "2560/2560 [==============================] - 88s 34ms/step - loss: 0.0269 - acc: 0.0014 - val_loss: 0.0083 - val_acc: 6.7017e-04\n",
      "Epoch 16/400\n",
      "2560/2560 [==============================] - 84s 33ms/step - loss: 0.0268 - acc: 0.0444 - val_loss: 0.0082 - val_acc: 8.3618e-04\n",
      "Epoch 17/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0267 - acc: 0.0015 - val_loss: 0.0082 - val_acc: 8.3618e-04\n",
      "Epoch 18/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0266 - acc: 0.0199 - val_loss: 0.0081 - val_acc: 8.3618e-04\n",
      "Epoch 19/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0265 - acc: 0.0015 - val_loss: 0.0081 - val_acc: 8.3374e-04\n",
      "Epoch 20/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0264 - acc: 0.0257 - val_loss: 0.0081 - val_acc: 8.2520e-04\n",
      "Epoch 21/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0263 - acc: 0.0466 - val_loss: 0.0080 - val_acc: 7.6660e-04\n",
      "Epoch 22/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0262 - acc: 0.0017 - val_loss: 0.0080 - val_acc: 5.8594e-04\n",
      "Epoch 23/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0261 - acc: 0.0017 - val_loss: 0.0080 - val_acc: 5.8594e-04\n",
      "Epoch 24/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0261 - acc: 0.0016 - val_loss: 0.0079 - val_acc: 5.2979e-04\n",
      "Epoch 25/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0260 - acc: 0.0016 - val_loss: 0.0079 - val_acc: 5.2979e-04\n",
      "Epoch 26/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0259 - acc: 0.0264 - val_loss: 0.0079 - val_acc: 5.3101e-04\n",
      "Epoch 27/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0258 - acc: 0.0015 - val_loss: 0.0078 - val_acc: 5.3101e-04\n",
      "Epoch 28/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0258 - acc: 0.0015 - val_loss: 0.0078 - val_acc: 5.3101e-04\n",
      "Epoch 29/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0257 - acc: 0.0015 - val_loss: 0.0078 - val_acc: 5.3101e-04\n",
      "Epoch 30/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0256 - acc: 0.0015 - val_loss: 0.0078 - val_acc: 5.3101e-04\n",
      "Epoch 31/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0256 - acc: 0.0197 - val_loss: 0.0077 - val_acc: 5.3101e-04\n",
      "Epoch 32/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0255 - acc: 0.0198 - val_loss: 0.0077 - val_acc: 5.3101e-04\n",
      "Epoch 33/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0255 - acc: 0.0015 - val_loss: 0.0077 - val_acc: 5.3101e-04\n",
      "Epoch 34/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0254 - acc: 0.0435 - val_loss: 0.0077 - val_acc: 5.3223e-04\n",
      "Epoch 35/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0254 - acc: 0.0744 - val_loss: 0.0076 - val_acc: 5.3223e-04\n",
      "Epoch 36/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0253 - acc: 0.0256 - val_loss: 0.0076 - val_acc: 5.3223e-04\n",
      "Epoch 37/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0252 - acc: 0.0014 - val_loss: 0.0076 - val_acc: 5.3223e-04\n",
      "Epoch 38/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0252 - acc: 0.0014 - val_loss: 0.0076 - val_acc: 5.3223e-04\n",
      "Epoch 39/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0251 - acc: 0.0014 - val_loss: 0.0075 - val_acc: 5.3223e-04\n",
      "Epoch 40/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0251 - acc: 0.0257 - val_loss: 0.0075 - val_acc: 5.3223e-04\n",
      "Epoch 41/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0251 - acc: 0.0232 - val_loss: 0.0075 - val_acc: 5.3467e-04\n",
      "Epoch 42/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0250 - acc: 0.0013 - val_loss: 0.0075 - val_acc: 5.3467e-04\n",
      "Epoch 43/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0250 - acc: 0.0013 - val_loss: 0.0075 - val_acc: 5.3467e-04\n",
      "Epoch 44/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0249 - acc: 0.0012 - val_loss: 0.0075 - val_acc: 5.3467e-04\n",
      "Epoch 45/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0249 - acc: 0.0013 - val_loss: 0.0074 - val_acc: 5.3467e-04\n",
      "Epoch 46/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0249 - acc: 0.0231 - val_loss: 0.0074 - val_acc: 5.3467e-04\n",
      "Epoch 47/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0248 - acc: 0.0010 - val_loss: 0.0074 - val_acc: 5.3467e-04\n",
      "Epoch 48/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0248 - acc: 0.0010 - val_loss: 0.0074 - val_acc: 5.3467e-04\n",
      "Epoch 49/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0247 - acc: 0.0010 - val_loss: 0.0074 - val_acc: 5.3467e-04\n",
      "Epoch 50/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0247 - acc: 0.0863 - val_loss: 0.0074 - val_acc: 5.4199e-04\n",
      "Epoch 51/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0247 - acc: 0.0011 - val_loss: 0.0073 - val_acc: 5.4565e-04\n",
      "Epoch 52/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0246 - acc: 0.0011 - val_loss: 0.0073 - val_acc: 5.4565e-04\n",
      "Epoch 53/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0246 - acc: 0.0011 - val_loss: 0.0073 - val_acc: 5.4565e-04\n",
      "Epoch 54/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0246 - acc: 0.0011 - val_loss: 0.0073 - val_acc: 5.4565e-04\n",
      "Epoch 55/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0246 - acc: 0.0011 - val_loss: 0.0073 - val_acc: 7.2876e-04\n",
      "Epoch 56/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0245 - acc: 0.0229 - val_loss: 0.0073 - val_acc: 7.2876e-04\n",
      "Epoch 57/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0245 - acc: 0.1199 - val_loss: 0.0073 - val_acc: 7.2876e-04\n",
      "Epoch 58/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0245 - acc: 0.0010 - val_loss: 0.0073 - val_acc: 7.2876e-04\n",
      "Epoch 59/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0245 - acc: 9.3781e-04 - val_loss: 0.0073 - val_acc: 7.2876e-04\n",
      "Epoch 60/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0244 - acc: 0.0021 - val_loss: 0.0072 - val_acc: 7.2876e-04\n",
      "Epoch 61/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0244 - acc: 0.0227 - val_loss: 0.0072 - val_acc: 7.2876e-04\n",
      "Epoch 62/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0244 - acc: 8.9569e-04 - val_loss: 0.0072 - val_acc: 9.3994e-04\n",
      "Epoch 63/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0244 - acc: 0.0037 - val_loss: 0.0072 - val_acc: 0.0025\n",
      "Epoch 64/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0244 - acc: 8.5724e-04 - val_loss: 0.0072 - val_acc: 9.3994e-04\n",
      "Epoch 65/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0243 - acc: 8.5510e-04 - val_loss: 0.0072 - val_acc: 9.3994e-04\n",
      "Epoch 66/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0243 - acc: 8.3893e-04 - val_loss: 0.0072 - val_acc: 9.3994e-04\n",
      "Epoch 67/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0243 - acc: 0.0230 - val_loss: 0.0072 - val_acc: 9.3994e-04\n",
      "Epoch 68/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0243 - acc: 7.8369e-04 - val_loss: 0.0072 - val_acc: 9.3628e-04\n",
      "Epoch 69/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0243 - acc: 7.6447e-04 - val_loss: 0.0072 - val_acc: 9.3384e-04\n",
      "Epoch 70/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0242 - acc: 0.0914 - val_loss: 0.0072 - val_acc: 0.9330\n",
      "Epoch 71/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0242 - acc: 0.0462 - val_loss: 0.0072 - val_acc: 9.3506e-04\n",
      "Epoch 72/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0242 - acc: 7.2174e-04 - val_loss: 0.0072 - val_acc: 8.7524e-04\n",
      "Epoch 73/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0242 - acc: 0.0711 - val_loss: 0.0071 - val_acc: 8.7646e-04\n",
      "Epoch 74/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0242 - acc: 7.3578e-04 - val_loss: 0.0071 - val_acc: 8.7646e-04\n",
      "Epoch 75/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0242 - acc: 7.2205e-04 - val_loss: 0.0071 - val_acc: 8.7402e-04\n",
      "Epoch 76/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0242 - acc: 0.0395 - val_loss: 0.0071 - val_acc: 8.7402e-04\n",
      "Epoch 77/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0242 - acc: 7.1167e-04 - val_loss: 0.0071 - val_acc: 8.7402e-04\n",
      "Epoch 78/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0241 - acc: 0.0431 - val_loss: 0.0071 - val_acc: 8.7402e-04\n",
      "Epoch 79/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0241 - acc: 7.0953e-04 - val_loss: 0.0071 - val_acc: 8.7402e-04\n",
      "Epoch 80/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0241 - acc: 0.0430 - val_loss: 0.0071 - val_acc: 8.7402e-04\n",
      "Epoch 81/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0241 - acc: 7.1320e-04 - val_loss: 0.0071 - val_acc: 8.6426e-04\n",
      "Epoch 82/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0241 - acc: 0.0250 - val_loss: 0.0071 - val_acc: 6.9092e-04\n",
      "Epoch 83/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0241 - acc: 6.3019e-04 - val_loss: 0.0071 - val_acc: 6.9092e-04\n",
      "Epoch 84/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0241 - acc: 6.2347e-04 - val_loss: 0.0071 - val_acc: 6.8970e-04\n",
      "Epoch 85/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0241 - acc: 0.0926 - val_loss: 0.0071 - val_acc: 6.8970e-04\n",
      "Epoch 86/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0241 - acc: 0.0884 - val_loss: 0.0071 - val_acc: 6.8970e-04\n",
      "Epoch 87/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0241 - acc: 5.5298e-04 - val_loss: 0.0071 - val_acc: 6.8970e-04\n",
      "Epoch 88/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0241 - acc: 0.0250 - val_loss: 0.0071 - val_acc: 7.1777e-04\n",
      "Epoch 89/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0240 - acc: 6.6437e-04 - val_loss: 0.0071 - val_acc: 7.1777e-04\n",
      "Epoch 90/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0240 - acc: 6.4636e-04 - val_loss: 0.0071 - val_acc: 7.1777e-04\n",
      "Epoch 91/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0240 - acc: 6.4240e-04 - val_loss: 0.0071 - val_acc: 7.1777e-04\n",
      "Epoch 92/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0240 - acc: 0.1128 - val_loss: 0.0071 - val_acc: 7.2144e-04\n",
      "Epoch 93/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0240 - acc: 6.5155e-04 - val_loss: 0.0071 - val_acc: 7.2144e-04\n",
      "Epoch 94/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0240 - acc: 6.9336e-04 - val_loss: 0.0071 - val_acc: 7.2144e-04\n",
      "Epoch 95/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0240 - acc: 6.4178e-04 - val_loss: 0.0071 - val_acc: 7.2266e-04\n",
      "Epoch 96/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0240 - acc: 6.2561e-04 - val_loss: 0.0071 - val_acc: 5.0659e-04\n",
      "Epoch 97/400\n",
      "2560/2560 [==============================] - 83s 32ms/step - loss: 0.0240 - acc: 0.0240 - val_loss: 0.0071 - val_acc: 0.9310\n",
      "Epoch 98/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0240 - acc: 0.0250 - val_loss: 0.0071 - val_acc: 5.0659e-04\n",
      "Epoch 99/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0240 - acc: 6.7993e-04 - val_loss: 0.0071 - val_acc: 4.9927e-04\n",
      "Epoch 100/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0240 - acc: 0.1243 - val_loss: 0.0071 - val_acc: 4.9927e-04\n",
      "Epoch 101/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0240 - acc: 0.0199 - val_loss: 0.0071 - val_acc: 4.9927e-04\n",
      "Epoch 102/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0240 - acc: 0.0010 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 103/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0240 - acc: 8.4625e-04 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 104/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0240 - acc: 0.0011 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 105/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0240 - acc: 0.0577 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 106/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0240 - acc: 0.0014 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 107/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0240 - acc: 0.0012 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 108/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0013 - val_loss: 0.0070 - val_acc: 4.9927e-04\n",
      "Epoch 109/400\n",
      "2560/2560 [==============================] - 76s 30ms/step - loss: 0.0239 - acc: 0.0014 - val_loss: 0.0070 - val_acc: 5.1758e-04\n",
      "Epoch 110/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0408 - val_loss: 0.0070 - val_acc: 5.1758e-04\n",
      "Epoch 111/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0012 - val_loss: 0.0070 - val_acc: 5.3833e-04\n",
      "Epoch 112/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0015 - val_loss: 0.0070 - val_acc: 6.0547e-04\n",
      "Epoch 113/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0507 - val_loss: 0.0070 - val_acc: 6.0547e-04\n",
      "Epoch 114/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0015 - val_loss: 0.0070 - val_acc: 6.0547e-04\n",
      "Epoch 115/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0029 - val_loss: 0.0070 - val_acc: 6.0425e-04\n",
      "Epoch 116/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0257 - val_loss: 0.0070 - val_acc: 6.0425e-04\n",
      "Epoch 117/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0016 - val_loss: 0.0070 - val_acc: 4.3579e-04\n",
      "Epoch 118/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0016 - val_loss: 0.0070 - val_acc: 4.3579e-04\n",
      "Epoch 119/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0013 - val_loss: 0.0070 - val_acc: 4.3579e-04\n",
      "Epoch 120/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0014 - val_loss: 0.0070 - val_acc: 4.3579e-04\n",
      "Epoch 121/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0012 - val_loss: 0.0070 - val_acc: 4.3579e-04\n",
      "Epoch 122/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0011 - val_loss: 0.0070 - val_acc: 4.3701e-04\n",
      "Epoch 123/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0014 - val_loss: 0.0070 - val_acc: 4.3701e-04\n",
      "Epoch 124/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0012 - val_loss: 0.0070 - val_acc: 4.3701e-04\n",
      "Epoch 125/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0011 - val_loss: 0.0070 - val_acc: 4.3823e-04\n",
      "Epoch 126/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0010 - val_loss: 0.0070 - val_acc: 4.3823e-04\n",
      "Epoch 127/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0015 - val_loss: 0.0070 - val_acc: 4.1016e-04\n",
      "Epoch 128/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0424 - val_loss: 0.0070 - val_acc: 4.1016e-04\n",
      "Epoch 129/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0016 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 130/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0240 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 131/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0263 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 132/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0257 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 133/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0239 - acc: 0.0192 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 134/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0014 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 135/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0017 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 136/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0015 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 137/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0029 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 138/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0503 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 139/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0020 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 140/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0269 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 141/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0018 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 142/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0016 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 143/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0017 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 144/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0664 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 145/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0239 - acc: 0.0021 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 146/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0667 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 147/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0021 - val_loss: 0.0070 - val_acc: 0.0016\n",
      "Epoch 148/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0028 - val_loss: 0.0070 - val_acc: 0.0017\n",
      "Epoch 149/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0249 - val_loss: 0.0070 - val_acc: 0.0017\n",
      "Epoch 150/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0275 - val_loss: 0.0070 - val_acc: 0.0015\n",
      "Epoch 151/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.0466 - val_loss: 0.0070 - val_acc: 0.0043\n",
      "Epoch 152/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0017 - val_loss: 0.0070 - val_acc: 0.0043\n",
      "Epoch 153/400\n",
      "2560/2560 [==============================] - 81s 31ms/step - loss: 0.0239 - acc: 0.0460 - val_loss: 0.0070 - val_acc: 0.0046\n",
      "Epoch 154/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.1418 - val_loss: 0.0070 - val_acc: 0.0046\n",
      "Epoch 155/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0017 - val_loss: 0.0070 - val_acc: 0.0046\n",
      "Epoch 156/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0016 - val_loss: 0.0070 - val_acc: 0.0046\n",
      "Epoch 157/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0239 - acc: 0.0019 - val_loss: 0.0070 - val_acc: 0.9426\n",
      "Epoch 158/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0700 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 159/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0020 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 160/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0052 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 161/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0690 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 162/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0516 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 163/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0239 - acc: 0.0460 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 164/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0026 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 165/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0239 - acc: 0.0027 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 166/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0244 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 167/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0239 - acc: 0.0249 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 168/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0239 - acc: 0.1445 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 169/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0031 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 170/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0034 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 171/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0034 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 172/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0036 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 173/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0283 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 174/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0034 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 175/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0037 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 176/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0224 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 177/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0225 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 178/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0039 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 179/400\n",
      "2560/2560 [==============================] - 76s 30ms/step - loss: 0.0238 - acc: 0.0036 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 180/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0036 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 181/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0436 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 182/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0038 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 183/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0038 - val_loss: 0.0070 - val_acc: 0.0051\n",
      "Epoch 184/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0042 - val_loss: 0.0070 - val_acc: 0.0056\n",
      "Epoch 185/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0042 - val_loss: 0.0070 - val_acc: 0.0056\n",
      "Epoch 186/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0260 - val_loss: 0.0070 - val_acc: 0.0056\n",
      "Epoch 187/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 188/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 189/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0046 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 190/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 191/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0043 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 192/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0042 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 193/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0298 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 194/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0043 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 195/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 196/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 197/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0056\n",
      "Epoch 198/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0044 - val_loss: 0.0070 - val_acc: 0.0056\n",
      "Epoch 199/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0045 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 200/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0047 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 201/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0045 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 202/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0049 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 203/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0294 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 204/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0050 - val_loss: 0.0070 - val_acc: 0.0057\n",
      "Epoch 205/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0049 - val_loss: 0.0070 - val_acc: 0.0056\n",
      "Epoch 206/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0051 - val_loss: 0.0070 - val_acc: 0.0055\n",
      "Epoch 207/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0271 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 208/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0053 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 209/400\n",
      "2560/2560 [==============================] - 76s 30ms/step - loss: 0.0238 - acc: 0.0050 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 210/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.1440 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 211/400\n",
      "2560/2560 [==============================] - 76s 30ms/step - loss: 0.0238 - acc: 0.1215 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 212/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0476 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 213/400\n",
      "2560/2560 [==============================] - 76s 30ms/step - loss: 0.0238 - acc: 0.0052 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 214/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0060 - val_loss: 0.0070 - val_acc: 0.0058\n",
      "Epoch 215/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0053 - val_loss: 0.0070 - val_acc: 0.0062\n",
      "Epoch 216/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0057 - val_loss: 0.0070 - val_acc: 0.0061\n",
      "Epoch 217/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0053 - val_loss: 0.0070 - val_acc: 0.0059\n",
      "Epoch 218/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0806 - val_loss: 0.0070 - val_acc: 0.0067\n",
      "Epoch 219/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0059 - val_loss: 0.0070 - val_acc: 0.0063\n",
      "Epoch 220/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0067 - val_loss: 0.0070 - val_acc: 0.0067\n",
      "Epoch 221/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0060 - val_loss: 0.0070 - val_acc: 0.0063\n",
      "Epoch 222/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0070 - val_loss: 0.0070 - val_acc: 0.0067\n",
      "Epoch 223/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0065 - val_loss: 0.0070 - val_acc: 0.0073\n",
      "Epoch 224/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0071 - val_loss: 0.0070 - val_acc: 0.0076\n",
      "Epoch 225/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0065 - val_loss: 0.0070 - val_acc: 0.0076\n",
      "Epoch 226/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0073 - val_loss: 0.0070 - val_acc: 0.0076\n",
      "Epoch 227/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0499 - val_loss: 0.0070 - val_acc: 0.0076\n",
      "Epoch 228/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0072 - val_loss: 0.0070 - val_acc: 0.0076\n",
      "Epoch 229/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0069 - val_loss: 0.0070 - val_acc: 0.0080\n",
      "Epoch 230/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0572 - val_loss: 0.0070 - val_acc: 0.0084\n",
      "Epoch 231/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0074 - val_loss: 0.0070 - val_acc: 0.0084\n",
      "Epoch 232/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0509 - val_loss: 0.0070 - val_acc: 0.0084\n",
      "Epoch 233/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.1656 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 234/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0714 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 235/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.1073 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 236/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0863 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 237/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0079 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 238/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0259 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 239/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0727 - val_loss: 0.0070 - val_acc: 0.9528\n",
      "Epoch 240/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0330 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 241/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0078 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 242/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0083 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 243/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0502 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 244/400\n",
      "2560/2560 [==============================] - 77s 30ms/step - loss: 0.0238 - acc: 0.0084 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 245/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0080 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 246/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0581 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 247/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0082 - val_loss: 0.0070 - val_acc: 0.0134\n",
      "Epoch 248/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0519 - val_loss: 0.0070 - val_acc: 0.0087\n",
      "Epoch 249/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0767 - val_loss: 0.0070 - val_acc: 0.0087\n",
      "Epoch 250/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0551 - val_loss: 0.0070 - val_acc: 0.0087\n",
      "Epoch 251/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0087 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 252/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0313 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 253/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0090 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 254/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0100 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 255/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0096 - val_loss: 0.0070 - val_acc: 0.9567\n",
      "Epoch 256/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0599 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 257/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0095 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 258/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.1043 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 259/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0320 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 260/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0105 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 261/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0101 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 262/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0103 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 263/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0101 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 264/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0106 - val_loss: 0.0070 - val_acc: 0.0083\n",
      "Epoch 265/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0102 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 266/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0112 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 267/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0105 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 268/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0344 - val_loss: 0.0070 - val_acc: 0.9575\n",
      "Epoch 269/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0355 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 270/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0118 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 271/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0109 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 272/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0122 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 273/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0111 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 274/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0123 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 275/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0115 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 276/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0112 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 277/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0120 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 278/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0117 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 279/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0549 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 280/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0124 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 281/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0120 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 282/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0136 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 283/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0125 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 284/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0117 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 285/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0124 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 286/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0126 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 287/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0776 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 288/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0120 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 289/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0126 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 290/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0127 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 291/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0128 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 292/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0602 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 293/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0131 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 294/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0130 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 295/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0133 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 296/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0356 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 297/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0139 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 298/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0582 - val_loss: 0.0070 - val_acc: 0.0091\n",
      "Epoch 299/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0140 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 300/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0823 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 301/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0551 - val_loss: 0.0070 - val_acc: 0.0109\n",
      "Epoch 302/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0992 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 303/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0839 - val_loss: 0.0070 - val_acc: 0.0095\n",
      "Epoch 304/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0333 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 305/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0150 - val_loss: 0.0070 - val_acc: 0.0113\n",
      "Epoch 306/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0166 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 307/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0130 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 308/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0170 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 309/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0325 - val_loss: 0.0070 - val_acc: 0.0113\n",
      "Epoch 310/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0167 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 311/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0131 - val_loss: 0.0070 - val_acc: 0.0114\n",
      "Epoch 312/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0182 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 313/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0132 - val_loss: 0.0070 - val_acc: 0.0114\n",
      "Epoch 314/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0178 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 315/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0147 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 316/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0435 - val_loss: 0.0070 - val_acc: 0.0114\n",
      "Epoch 317/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0403 - val_loss: 0.0070 - val_acc: 0.0095\n",
      "Epoch 318/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0197 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 319/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0156 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 320/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0196 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 321/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0158 - val_loss: 0.0070 - val_acc: 0.0095\n",
      "Epoch 322/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0198 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 323/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0625 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 324/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0180 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 325/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0159 - val_loss: 0.0070 - val_acc: 0.0095\n",
      "Epoch 326/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0184 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 327/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.1841 - val_loss: 0.0070 - val_acc: 0.0094\n",
      "Epoch 328/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0180 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 329/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0183 - val_loss: 0.0070 - val_acc: 0.0099\n",
      "Epoch 330/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0877 - val_loss: 0.0070 - val_acc: 0.0117\n",
      "Epoch 331/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0193 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 332/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0222 - val_loss: 0.0070 - val_acc: 0.0121\n",
      "Epoch 333/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0214 - val_loss: 0.0070 - val_acc: 0.0103\n",
      "Epoch 334/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0196 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 335/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0202 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 336/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0214 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 337/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0203 - val_loss: 0.0070 - val_acc: 0.0103\n",
      "Epoch 338/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0405 - val_loss: 0.0070 - val_acc: 0.0121\n",
      "Epoch 339/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0205 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 340/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0451 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 341/400\n",
      "2560/2560 [==============================] - 84s 33ms/step - loss: 0.0238 - acc: 0.0208 - val_loss: 0.0070 - val_acc: 0.0122\n",
      "Epoch 342/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0233 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 343/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0188 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 344/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0223 - val_loss: 0.0070 - val_acc: 0.0121\n",
      "Epoch 345/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0203 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 346/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0398 - val_loss: 0.0070 - val_acc: 0.0121\n",
      "Epoch 347/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0423 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 348/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0225 - val_loss: 0.0069 - val_acc: 0.0121\n",
      "Epoch 349/400\n",
      "2560/2560 [==============================] - 81s 31ms/step - loss: 0.0238 - acc: 0.0649 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 350/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0229 - val_loss: 0.0070 - val_acc: 0.0121\n",
      "Epoch 351/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0209 - val_loss: 0.0070 - val_acc: 0.0102\n",
      "Epoch 352/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0220 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 353/400\n",
      "2560/2560 [==============================] - 84s 33ms/step - loss: 0.0238 - acc: 0.0786 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 354/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0493 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 355/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0196 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 356/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0220 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 357/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0209 - val_loss: 0.0070 - val_acc: 0.0121\n",
      "Epoch 358/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0223 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 359/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0217 - val_loss: 0.0069 - val_acc: 0.0121\n",
      "Epoch 360/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0659 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 361/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0442 - val_loss: 0.0069 - val_acc: 0.0121\n",
      "Epoch 362/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0221 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 363/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0228 - val_loss: 0.0069 - val_acc: 0.0124\n",
      "Epoch 364/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.1900 - val_loss: 0.0069 - val_acc: 0.0102\n",
      "Epoch 365/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0211 - val_loss: 0.0069 - val_acc: 0.0136\n",
      "Epoch 366/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0420 - val_loss: 0.0069 - val_acc: 0.0106\n",
      "Epoch 367/400\n",
      "2560/2560 [==============================] - 80s 31ms/step - loss: 0.0238 - acc: 0.0249 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 368/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.1154 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 369/400\n",
      "2560/2560 [==============================] - 82s 32ms/step - loss: 0.0238 - acc: 0.0212 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 370/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0244 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 371/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0207 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 372/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0233 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 373/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0211 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 374/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0242 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 375/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0224 - val_loss: 0.0069 - val_acc: 0.0125\n",
      "Epoch 376/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0228 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 377/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0229 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 378/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0231 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 379/400\n",
      "2560/2560 [==============================] - 83s 33ms/step - loss: 0.0238 - acc: 0.0220 - val_loss: 0.0069 - val_acc: 0.0125\n",
      "Epoch 380/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0235 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 381/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0894 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 382/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0736 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 383/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0208 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 384/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0537 - val_loss: 0.0069 - val_acc: 0.0125\n",
      "Epoch 385/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0402 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 386/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0702 - val_loss: 0.0069 - val_acc: 0.0110\n",
      "Epoch 387/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0212 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 388/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0288 - val_loss: 0.0069 - val_acc: 0.0113\n",
      "Epoch 389/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0876 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 390/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0268 - val_loss: 0.0069 - val_acc: 0.0114\n",
      "Epoch 391/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0216 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 392/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0257 - val_loss: 0.0069 - val_acc: 0.0113\n",
      "Epoch 393/400\n",
      "2560/2560 [==============================] - 78s 30ms/step - loss: 0.0238 - acc: 0.0253 - val_loss: 0.0069 - val_acc: 0.0129\n",
      "Epoch 394/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0234 - val_loss: 0.0069 - val_acc: 0.0113\n",
      "Epoch 395/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0229 - val_loss: 0.0069 - val_acc: 0.0132\n",
      "Epoch 396/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0838 - val_loss: 0.0069 - val_acc: 0.0113\n",
      "Epoch 397/400\n",
      "2560/2560 [==============================] - 79s 31ms/step - loss: 0.0238 - acc: 0.0231 - val_loss: 0.0069 - val_acc: 0.0132\n",
      "Epoch 398/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0243 - val_loss: 0.0069 - val_acc: 0.0113\n",
      "Epoch 399/400\n",
      "2560/2560 [==============================] - 78s 31ms/step - loss: 0.0238 - acc: 0.0251 - val_loss: 0.0069 - val_acc: 0.0132\n",
      "Epoch 400/400\n",
      "2560/2560 [==============================] - 81s 32ms/step - loss: 0.0238 - acc: 0.0754 - val_loss: 0.0069 - val_acc: 0.0114\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1280, 64), return_sequences=True))\n",
    "model.summary()\n",
    "adam = Adam(lr=0.00005)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_error', metrics=['acc'])\n",
    "\n",
    "# Fitting the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=400,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyd0wDKMO+f8oZfoZEa7aRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f610c5ed358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xt8VOW97/HPj4SLctWAW0vUgPpS\nIQZII+IRRcW6UauopRWM161Fse7a2p4jWrVI697eqharVrzVCooee1S21VIV3GjbDQS5CCISNdQI\nSoiCIHgJ/M4f65k4xElmkkwySeb7fr3Wa9blWc/6rRWY36znWRdzd0RERDplOgAREWkblBBERARQ\nQhARkUAJQUREACUEEREJlBBERARQQpA0MrMcM9tqZvuls2wmmdmBZpb2a7PN7AQzq4ibXm1mR6dS\ntgnbesDMrmnq+g3U+2sz+0O665XMyc10AJI5ZrY1bnJ34AtgR5i+xN1nNqY+d98B9Eh32Wzg7gen\nox4zuxg4x92Pjav74nTULR2fEkIWc/faL+TwC/Rid3+pvvJmluvuNa0Rm4i0PjUZSb1Ck8ATZva4\nmW0BzjGzI83sf8xsk5mtN7NpZtY5lM81MzezgjA9Iyx/wcy2mNk/zGxAY8uG5SeZ2dtmttnM7jKz\nv5nZBfXEnUqMl5hZuZl9YmbT4tbNMbM7zKzazN4BxjRwfK41s1l15t1tZreH8YvNbFXYn3fCr/f6\n6qo0s2PD+O5m9miIbSXw7QTbfTfUu9LMTgvzDwN+BxwdmuM2xh3bKXHrXxr2vdrMnjGzfVI5NsmY\n2ekhnk1mNtfMDo5bdo2ZrTOzT83srbh9HWFmr4f5H5nZraluT1qAu2vQAFABnFBn3q+BL4FTiX48\n7AYcDhxBdHY5EHgbuDyUzwUcKAjTM4CNQAnQGXgCmNGEsnsBW4CxYdmVwFfABfXsSyoxPgv0BgqA\nj2P7DlwOrATygTxgfvTfJOF2BgJbge5xdW8ASsL0qaGMAccD24GisOwEoCKurkrg2DB+G/AKsAew\nP/BmnbI/APYJf5OzQwz/EpZdDLxSJ84ZwJQwfmKIcSjQDbgHmJvKsUmw/78G/hDGDw1xHB/+RteE\n494ZGAysBfYOZQcAA8P4ImBCGO8JHJHp/wvZPOgMQZJ5zd3/y913uvt2d1/k7gvcvcbd3wWmA6Ma\nWP8pdy9z96+AmURfRI0t+11gqbs/G5bdQZQ8Ekoxxv90983uXkH05Rvb1g+AO9y90t2rgZsa2M67\nwAqiRAXwHWCTu5eF5f/l7u96ZC7wMpCw47iOHwC/dvdP3H0t0a/++O0+6e7rw9/kMaJkXpJCvQCl\nwAPuvtTdPwcmA6PMLD+uTH3HpiHjgdnuPjf8jW4CehEl5hqi5DM4NDu+F44dRIn9IDPLc/ct7r4g\nxf2QFqCEIMm8Hz9hZoeY2Z/N7EMz+xSYCvRtYP0P48a30XBHcn1lvxUfh7s70S/qhFKMMaVtEf2y\nbchjwIQwfjZRIovF8V0zW2BmH5vZJqJf5w0dq5h9GorBzC4ws2WhaWYTcEiK9UK0f7X1ufunwCdA\n/7gyjfmb1VfvTqK/UX93Xw38jOjvsCE0Qe4dil4IDAJWm9lCMzs5xf2QFqCEIMnUveTyPqJfxQe6\ney/geqImkZa0nqgJBwAzM3b9AqurOTGuB/aNm052WewTwAnhF/ZYogSBme0GPAX8J1FzTh/grynG\n8WF9MZjZQOBeYBKQF+p9K67eZJfIriNqhorV15OoaeqDFOJqTL2diP5mHwC4+wx3P4qouSiH6Ljg\n7qvdfTxRs+BvgD+ZWbdmxiJNpIQgjdUT2Ax8ZmaHApe0wjafA4rN7FQzywWuAPq1UIxPAj8xs/5m\nlgdc1VBhd/8IeA14GFjt7mvCoq5AF6AK2GFm3wVGNyKGa8ysj0X3aVwet6wH0Zd+FVFuvJjoDCHm\nIyA/1omewOPARWZWZGZdib6YX3X3es+4GhHzaWZ2bNj2/ybq91lgZoea2XFhe9vDsINoB841s77h\njGJz2LedzYxFmkgJQRrrZ8D5RP/Z7yP6hdyiwpfuWcDtQDVwALCE6L6JdMd4L1Fb/xtEHZ5PpbDO\nY0SdxI/FxbwJ+CnwNFHH7DiixJaKXxKdqVQALwB/jKt3OTANWBjKHALEt7u/CKwBPjKz+Kaf2Pp/\nIWq6eTqsvx9Rv0KzuPtKomN+L1GyGgOcFvoTugK3EPX7fEh0RnJtWPVkYJVFV7HdBpzl7l82Nx5p\nGouaY0XaDzPLIWqiGOfur2Y6HpGOQmcI0i6Y2Rgz6x2aHa4junJlYYbDEulQlBCkvRgJvEvU7DAG\nON3d62syEpEmUJORiIgAOkMQEZGgXT3crm/fvl5QUJDpMERE2pXFixdvdPeGLtUG2llCKCgooKys\nLNNhiIi0K2aW7I57QE1GIiISKCGIiAighCAiIkG76kMQkdb11VdfUVlZyeeff57pUCQF3bp1Iz8/\nn86d63uUVcOUEESkXpWVlfTs2ZOCggKih8xKW+XuVFdXU1lZyYABA5KvkECHbzKaORMKCqBTp+hz\nZqNeGy+S3T7//HPy8vKUDNoBMyMvL69ZZ3Md+gxh5kyYOBG2bYum166NpgFKm/18R5HsoGTQfjT3\nb9WhzxB+8Yuvk0HMtm3RfBER2VWHTgj//Gfj5otI21JdXc3QoUMZOnQoe++9N/3796+d/vLL1F6b\ncOGFF7J69eoGy9x9993MTFN78siRI1m6dGla6mptHbrJaL/9omaiRPNFJP1mzozOwP/5z+j/2Y03\nNq95Ni8vr/bLdcqUKfTo0YOf//znu5Rxd9ydTp0S/759+OGHk27nRz/6UdOD7EA69BnCjTfC7rvv\nOm/33aP5IpJesT67tWvB/es+u5a4kKO8vJzCwkIuvfRSiouLWb9+PRMnTqSkpITBgwczderU2rKx\nX+w1NTX06dOHyZMnM2TIEI488kg2bNgAwLXXXsudd95ZW37y5MkMHz6cgw8+mL///e8AfPbZZ3zv\ne99jyJAhTJgwgZKSkqRnAjNmzOCwww6jsLCQa665BoCamhrOPffc2vnTpk0D4I477mDQoEEMGTKE\nc845J+3HLBUdOiGUlsL06bD//mAWfU6frg5lkZbQ2n12b775JhdddBFLliyhf//+3HTTTZSVlbFs\n2TJefPFF3nzzzW+ss3nzZkaNGsWyZcs48sgjeeihhxLW7e4sXLiQW2+9tTa53HXXXey9994sW7aM\nyZMns2TJkgbjq6ys5Nprr2XevHksWbKEv/3tbzz33HMsXryYjRs38sYbb7BixQrOO+88AG655RaW\nLl3KsmXL+N3vftfMo9M0HTohQPTlX1EBO3dGn0oGIi2jtfvsDjjgAA4//PDa6ccff5zi4mKKi4tZ\ntWpVwoSw2267cdJJJwHw7W9/m4qKioR1n3nmmd8o89prrzF+/HgAhgwZwuDBgxuMb8GCBRx//PH0\n7duXzp07c/bZZzN//nwOPPBAVq9ezRVXXMGcOXPo3bs3AIMHD+acc85h5syZTb6xrLk6fEIQkdZR\nX99cS/XZde/evXZ8zZo1/Pa3v2Xu3LksX76cMWPGJLwev0uXLrXjOTk51NTUJKy7a9eu3yjT2JeJ\n1Vc+Ly+P5cuXM3LkSKZNm8Yll1wCwJw5c7j00ktZuHAhJSUl7Nixo1HbS4eUEkJ4n+1qMys3s8kJ\nlnc1syfC8gVmVhDmDzezpWFYZmZnxK1TYWZvhGV6prVIO5fJPrtPP/2Unj170qtXL9avX8+cOXPS\nvo2RI0fy5JNPAvDGG28kPAOJN2LECObNm0d1dTU1NTXMmjWLUaNGUVVVhbvz/e9/nxtuuIHXX3+d\nHTt2UFlZyfHHH8+tt95KVVUV2+q2v7WCpFcZmVkOcDfwHaASWGRms909/mhcBHzi7gea2XjgZuAs\nYAVQ4u41ZrYPsMzM/svdY2n5OHffmM4dEpHMiDXHpvMqo1QVFxczaNAgCgsLGThwIEcddVTat/Hv\n//7vnHfeeRQVFVFcXExhYWFtc08i+fn5TJ06lWOPPRZ359RTT+WUU07h9ddf56KLLsLdMTNuvvlm\nampqOPvss9myZQs7d+7kqquuomfPnmnfh2SSvlPZzI4Eprj7v4bpqwHc/T/jyswJZf5hZrnAh0A/\nj6vczAYA/wP0DwmigihZpJwQSkpKXC/IEWk9q1at4tBDD810GG1CTU0NNTU1dOvWjTVr1nDiiSey\nZs0acnPb1tX7if5mZrbY3UuSrZvKnvQH3o+brgSOqK9M+LLfDOQBG83sCOAhYH/g3LizAwf+amYO\n3Ofu0xNt3MwmAhMB9tMNBCKSIVu3bmX06NHU1NTg7tx3331tLhk0Vyp7k+jhGHVPK+ot4+4LgMFm\ndijwiJm94O6fA0e5+zoz2wt40czecvf536gkShTTITpDSCFeEZG069OnD4sXL850GC0qlU7lSmDf\nuOl8YF19ZUKTUW/g4/gC7r4K+AwoDNPrwucG4GlgeOPDFxGRdEklISwCDjKzAWbWBRgPzK5TZjZw\nfhgfB8x1dw/r5AKY2f7AwUCFmXU3s55hfnfgRKIOaBERyZCkTUahT+ByYA6QAzzk7ivNbCpQ5u6z\ngQeBR82snOjMYHxYfSQw2cy+AnYCl7n7RjMbCDwdHtWaCzzm7n9J986JiEjqUuoRcffngefrzLs+\nbvxz4PsJ1nsUeDTB/HeBIY0NtqnS/cAtEZGOqMPfqdyaD9wSkfQ69thjv3GT2Z133slll13W4Ho9\nevQAYN26dYwbN67eupNdxn7nnXfucoPYySefzKZNm1IJvUFTpkzhtttua3Y96dbhE4JekiPSfk2Y\nMIFZs2btMm/WrFlMmDAhpfW/9a1v8dRTTzV5+3UTwvPPP0+fPn2aXF9b1+ETgl6SI9J+jRs3juee\ne44vvvgCgIqKCtatW8fIkSNr7wsoLi7msMMO49lnn/3G+hUVFRQWFgKwfft2xo8fT1FREWeddRbb\nt2+vLTdp0qTaR2f/8pe/BGDatGmsW7eO4447juOOOw6AgoICNm6M7qW9/fbbKSwspLCwsPbR2RUV\nFRx66KH88Ic/ZPDgwZx44om7bCeRpUuXMmLECIqKijjjjDP45JNParc/aNAgioqKah+q99///d+1\nLwgaNmwYW7ZsafKxTaRj3VWRgF6SI5IeP/kJpPtFYEOHQvguTSgvL4/hw4fzl7/8hbFjxzJr1izO\nOusszIxu3brx9NNP06tXLzZu3MiIESM47bTT6n2v8L333svuu+/O8uXLWb58OcXFxbXLbrzxRvbc\nc0927NjB6NGjWb58OT/+8Y+5/fbbmTdvHn379t2lrsWLF/Pwww+zYMEC3J0jjjiCUaNGsccee7Bm\nzRoef/xx7r//fn7wgx/wpz/9qcH3G5x33nncddddjBo1iuuvv54bbriBO++8k5tuuon33nuPrl27\n1jZT3Xbbbdx9990cddRRbN26lW7dujXiaCfX4c8Q9JIckfYtvtkovrnI3bnmmmsoKirihBNO4IMP\nPuCjjz6qt5758+fXfjEXFRVRVFRUu+zJJ5+kuLiYYcOGsXLlyqQPrnvttdc444wz6N69Oz169ODM\nM8/k1VdfBWDAgAEMHToUaPgR2xC9n2HTpk2MGjUKgPPPP5/58+fXxlhaWsqMGTNq74g+6qijuPLK\nK5k2bRqbNm1K+53SHf4MIZMP3BLpSBr6Jd+STj/9dK688kpef/11tm/fXvvLfubMmVRVVbF48WI6\nd+5MQUFBwkdex0t09vDee+9x2223sWjRIvbYYw8uuOCCpPU09Ay42KOzIXp8drImo/r8+c9/Zv78\n+cyePZtf/epXrFy5ksmTJ3PKKafw/PPPM2LECF566SUOOeSQJtWfSIc/QwC9JEekPevRowfHHnss\n//Zv/7ZLZ/LmzZvZa6+96Ny5M/PmzWNtorbhOMcccwwzw+WFK1asYPny5UD06Ozu3bvTu3dvPvro\nI1544YXadXr27Jmwnf6YY47hmWeeYdu2bXz22Wc8/fTTHH300Y3et969e7PHHnvUnl08+uijjBo1\nip07d/L+++9z3HHHccstt7Bp0ya2bt3KO++8w2GHHcZVV11FSUkJb731VqO32ZAOf4YgIu3fhAkT\nOPPMM3e54qi0tJRTTz2VkpIShg4dmvSX8qRJk7jwwgspKipi6NChDB8ePS1nyJAhDBs2jMGDB3/j\n0dkTJ07kpJNOYp999mHevHm184uLi7ngggtq67j44osZNmxYg81D9XnkkUe49NJL2bZtGwMHDuTh\nhx9mx44dnHPOOWzevBl356c//Sl9+vThuuuuY968eeTk5DBo0KDat7+lS9LHX7clevy1SOvS46/b\nn+Y8/jormoxERCS5rEgIM2dCQQF06hR96i5lEZFv6vB9CLFHV8RuNow9ugLUuSySitirHqXta24X\nQIc/Q9CjK0Sarlu3blRXVzf7i0ZanrtTXV3drJvVOvwZgh5dIdJ0+fn5VFZWUlVVlelQJAXdunUj\nPz+/yet3+ISgR1eINF3nzp0ZMGBApsOQVtLhm4z06AoRkdR0+IRQWgrTp8P++4NZ9Dl9ujqURUTq\n6vBNRhB9+SsBiIg0rMOfIcToXgQRkYZlxRmC7kUQEUkuK84QdC+CiEhyWZEQdC+CiEhyWZEQ6rvn\nQPciiIh8LSsSgu5FEBFJLqWEYGZjzGy1mZWb2eQEy7ua2RNh+QIzKwjzh5vZ0jAsM7MzUq0znWL3\nIuTlfT1vt91acosiIu1P0oRgZjnA3cBJwCBggpkNqlPsIuATdz8QuAO4OcxfAZS4+1BgDHCfmeWm\nWGfaxb/atLo6utJIl5+KiERSOUMYDpS7+7vu/iUwCxhbp8xY4JEw/hQw2szM3be5e02Y3w2IPTIx\nlTrTSlcaiYg0LJWE0B94P266MsxLWCYkgM1AHoCZHWFmK4E3gEvD8lTqTCtdaSQi0rBUEkKiN2PU\nfTh6vWXcfYG7DwYOB642s24p1hlVbDbRzMrMrKw5j+DVlUYiIg1LJSFUAvvGTecD6+orY2a5QG/g\n4/gC7r4K+AwoTLHO2HrT3b3E3Uv69euXQriJJbrSyAxOPrnJVYqIdCipJIRFwEFmNsDMugDjgdl1\nyswGzg/j44C57u5hnVwAM9sfOBioSLHOtCothfPPj5JAjDs88og6lkVEIIWEENr8LwfmAKuAJ919\npZlNNbPTQrEHgTwzKweuBGKXkY4ElpnZUuBp4DJ331hfnencsUSefz5KAvHUsSwiErH29K7UkpIS\nLysra/L6nTp9MyFAdNawc2czAhMRacPMbLG7lyQrlxV3KsfsuWfj5ouIZJOsSggiIlK/rEoIH3+c\neH51devGISLSFmVVQqjvngMzXWkkIpJVCeHGG3e97DTGXVcaiYhkVUIoLU18lRFEr9UUEclmWZUQ\nAPbfP/F8NRuJSLbLuoTQULPRFVe0fjwiIm1F1iWEhpqNqqvhsstaNx4RkbYi6xIC1N9sBPD736vp\nSESyU1YmhIbepawrjkQkW2VlQigt3fX9ynXpiiMRyUZZmRAAfvvbhpf37KmmIxHJLlmbEEpLG16+\ndWv0/gQlBRHJFlmbEKDhzmWAHTvgkktaJxYRkUzL6oRQ3z0J8T77TM1HIpIdsjohlJbCpZcmL7d1\nK5xzju5REJGOLasTAsA998CkSamVvfdeJQUR6biyPiFA45PCCSe0bDwiIpmghBA0Jim8/DLstpv6\nFUSkY1FCiNOYpPD551G/gjqcRaSjUEKoozFJAb7ucFZiEJH2TgkhgXvugRkzoHv31NeJJQb1L4hI\ne6WEUI/S0uhLfvToxq338svRvQ19++qMQUTaFyWEJF56qfFJAaJ3K6gpSUTak5QSgpmNMbPVZlZu\nZpMTLO9qZk+E5QvMrCDM/46ZLTazN8Ln8XHrvBLqXBqGvdK1U+n20kuNb0KKiTUl6aokEWnrkiYE\nM8sB7gZOAgYBE8xsUJ1iFwGfuPuBwB3AzWH+RuBUdz8MOB94tM56pe4+NAwbmrEfLS7WhNSYDud4\nsauSzHTWICJtUypnCMOBcnd/192/BGYBY+uUGQs8EsafAkabmbn7EndfF+avBLqZWdd0BJ4psQ7n\nht6nkEzsrMFMCUJE2o5UEkJ/4P246cowL2EZd68BNgN1vzK/Byxx9y/i5j0cmouuM0v8mDkzm2hm\nZWZWVlVVlUK4La+0FDZujN6u1pT+hbrqJgh1SItIJqSSEBJ9Udd9TX2DZcxsMFEzUvzDpEtDU9LR\nYTg30cbdfbq7l7h7Sb9+/VIIt3U1p3+hPrEO6ViCyMnRM5REpOWlkhAqgX3jpvOBdfWVMbNcoDfw\ncZjOB54GznP3d2IruPsH4XML8BhR01S7FOtfaG5TUn127oyeoRRLEPGDkoWIpEsqCWERcJCZDTCz\nLsB4YHadMrOJOo0BxgFz3d3NrA/wZ+Bqd/9brLCZ5ZpZ3zDeGfgusKJ5u5J58U1JTe18bqyGkoWS\nhog0RtKEEPoELgfmAKuAJ919pZlNNbPTQrEHgTwzKweuBGKXpl4OHAhcV+fy0q7AHDNbDiwFPgDu\nT+eOZdo990SJId3NSU2RStJo6qD+DpGOw9zrdge0XSUlJV5WVpbpMJps5ky44oqoj0BEpDE6dYpe\n6XvPPY1f18wWu3tJ0m00JTBpmvgmpbZy9iAi7UPsTL8lm3+VEDIo1hkdSxCTJiV/x7OIZLfp01uu\nbiWENuSee6JfAfFnEC1x1ZKItF87drRc3UoIbVjdJqb4QclCJDvl5LRc3UoI7VRDyUJJQ6Tjmjix\n5epWQujAUkkaTRmUaERaX6dOUT9jU64ySlVuy1UtHVVpaTSISMeiMwQREQGUEEREJFBCEBERQAlB\nREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBC\nEBERQAlBREQCJQQREQGUEEREJEgpIZjZGDNbbWblZjY5wfKuZvZEWL7AzArC/O+Y2WIzeyN8Hh+3\nzrfD/HIzm2Zmlq6dEhGRxkuaEMwsB7gbOAkYBEwws0F1il0EfOLuBwJ3ADeH+RuBU939MOB84NG4\nde4FJgIHhWFMM/ZDRESaKZUzhOFAubu/6+5fArOAsXXKjAUeCeNPAaPNzNx9ibuvC/NXAt3C2cQ+\nQC93/4e7O/BH4PRm742IiDRZKgmhP/B+3HRlmJewjLvXAJuBvDplvgcscfcvQvnKJHUCYGYTzazM\nzMqqqqpSCFdERJoilYSQqG3fG1PGzAYTNSNd0og6o5nu0929xN1L+vXrl0K4IiLSFKkkhEpg37jp\nfGBdfWXMLBfoDXwcpvOBp4Hz3P2duPL5SeoUEZFWlEpCWAQcZGYDzKwLMB6YXafMbKJOY4BxwFx3\ndzPrA/wZuNrd/xYr7O7rgS1mNiJcXXQe8Gwz90VERJohaUIIfQKXA3OAVcCT7r7SzKaa2Wmh2INA\nnpmVA1cCsUtTLwcOBK4zs6Vh2CssmwQ8AJQD7wAvpGunRESk8Sy6yKd9KCkp8bKyskyHISLSrpjZ\nYncvSVZOdyqLiAighCAiIoESgoiIAEoIIiISKCGIiAighCAiIoESgoiIAEoIIiISKCGIiAighCAi\nIoESgoiIAEoIIiISKCGIiAighCAiIoESgoiIAEoIIiISKCGIiAighCAiIoESgoiIAEoIIiISKCGI\niAighCAiIoESgoiIAEoIIiISKCGIiAiQYkIwszFmttrMys1scoLlXc3sibB8gZkVhPl5ZjbPzLaa\n2e/qrPNKqHNpGPZKxw6JiEjT5CYrYGY5wN3Ad4BKYJGZzXb3N+OKXQR84u4Hmtl44GbgLOBz4Dqg\nMAx1lbp7WTP3QURE0iCVM4ThQLm7v+vuXwKzgLF1yowFHgnjTwGjzczc/TN3f40oMYiISBuWSkLo\nD7wfN10Z5iUs4+41wGYgL4W6Hw7NRdeZmSUqYGYTzazMzMqqqqpSqFJERJoilYSQ6Ivam1CmrlJ3\nPww4OgznJirk7tPdvcTdS/r165c0WBERaZpUEkIlsG/cdD6wrr4yZpYL9AY+bqhSd/8gfG4BHiNq\nmhIRkQxJJSEsAg4yswFm1gUYD8yuU2Y2cH4YHwfMdfd6zxDMLNfM+obxzsB3gRWNDV5ERNIn6VVG\n7l5jZpcDc4Ac4CF3X2lmU4Eyd58NPAg8amblRGcG42Prm1kF0AvoYmanAycCa4E5IRnkAC8B96d1\nz0REpFGsgR/ybU5JSYmXlekqVRGRxjCzxe5ekqyc7lQWERFACUFERAIlBBERAZQQREQkUEIQERFA\nCUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAbIkIVx/\nPfz+95mOQkSkbcuKhPDCC/DMM5mOQkSkbcuKhDBwILz7bqajEBFp27ImIVRUwI4dmY5ERKTtypqE\n8NVXUFmZ6UhERNqurEkIoGYjEZGGZFVCeOedzMYhItKWZUVC2G8/2H13WLEi05GIiLRdWZEQcnKg\nqAiWLMl0JCIibVdKCcHMxpjZajMrN7PJCZZ3NbMnwvIFZlYQ5ueZ2Twz22pmv6uzzrfN7I2wzjQz\ns3TsUH2GDYOlS2HnzpbciohI+5U0IZhZDnA3cBIwCJhgZoPqFLsI+MTdDwTuAG4O8z8HrgN+nqDq\ne4GJwEFhGNOUHUjVsGHw6afqWBYRqU8qZwjDgXJ3f9fdvwRmAWPrlBkLPBLGnwJGm5m5+2fu/hpR\nYqhlZvsAvdz9H+7uwB+B05uzI8kceWT0+eqrLbkVEZH2K5WE0B94P266MsxLWMbda4DNQF6SOuPv\nCkhUJwBmNtHMysysrKqqKoVwExs8GPbaC+bObXIVIiIdWioJIVHbvjehTJPKu/t0dy9x95J+/fo1\nUGXDzOD44+Gll9SPICKSSCoJoRLYN246H1hXXxkzywV6Ax8nqTM/SZ1pd8op8OGH8I9/tPSWRETa\nn1QSwiLgIDMbYGZdgPHA7DplZgPnh/FxwNzQN5CQu68HtpjZiHB10XnAs42OvpFOOw26doUnnmjp\nLYmItD9JE0LoE7gcmAOsAp7Fh2uJAAAIXklEQVR095VmNtXMTgvFHgTyzKwcuBKovTTVzCqA24EL\nzKwy7gqlScADQDnwDvBCenapfr16wdixMGMGbNvW0lsTEWlfrIEf8m1OSUmJl5WVNauO+fNh1Ci4\n5x6YNClNgYmItGFmttjdS5KVy4o7leMdfTT8r/8Fv/oVbN2a6WhERNqOrEsIZvCb30Sdyz/5CbSj\nEyQRkRaVdQkBYMQImDwZHnwQpkzJdDQiIm1DbqYDyJRf/xo++gimToUNG+DWW6FHj0xHJSKSOVl5\nhgDQqRPcfz/87Gdw331QWAgPPABffpnpyEREMiNrEwJESeG22+CVV6BvX/jhD6OX6UyZoofgiUj2\nyeqEEHPMMbBoEcyZA4ceGjUjHXBAdEXSXXfBP/+Z6QhFRFqeEkJgBieeCC++CGvXwn/8B1RXw49/\nDPvvD8XFcMMN0WMvamoyHa2ISPpl3Y1pjfX22/Dss/DMM1EycIeePaOb20aPjj4LC6Fz51YNS0Qk\nZanemKaE0AjV1TBvXvTE1JdfhvLyaH63btEZxPDhcPjh0ecBB0RnHSIimaaE0ArWroW//z3qf1i0\nCBYvhu3bo2W9esEhh8CgQVG/RGwYMCB6x7OISGtRQsiAmhp4801YuDB6f/OqVdGwfv3XZTp3hn33\njfol6g75+dCvH/Tpo7MLEUmfVBNC1t6Y1hJyc6GoKBribdr0dXJ4++3ozGLtWvjrX6NkUTcn5+ZG\niSE27LVX9LnnnlGy2GOP6LN3b+jeHXbffddht910FiIijaeE0Ar69Ine6Rx7r3O8L7+E99+PLm39\n4AOoqoqGDRu+Hl+4MPr89NPUt9mlyzcTRWzo2jVKOvFD587fnJfqEL9up067DmaNm27KOrGzqXR8\nZkNdIvVRQsiwLl2iDugDDkhetqYGNm+Ozjg++SQa37Yt6rfYtu2bQ6L527fDli1RXcmGr77adVo6\nlraasNpCXU1V3/rpmL9kSfRjriUpIbQjubmQlxcNrc09ehd1Q0njq6+iMrGysSHZdFPWiU3v2PF1\nfM39TEcd2VRXW4+vqes2VX3rp2t+a5zdKSFISsyifomcnJb/lSIimaE7lUVEBFBCEBGRQAlBREQA\nJQQREQmUEEREBFBCEBGRQAlBREQAJQQREQna1dNOzawKWNuEVfsCG9McTjoorsZrq7EprsZRXI3T\n3Lj2d/d+yQq1q4TQVGZWlsqjX1ub4mq8thqb4mocxdU4rRWXmoxERARQQhARkSBbEsL0TAdQD8XV\neG01NsXVOIqrcVolrqzoQxARkeSy5QxBRESSUEIQEREgCxKCmY0xs9VmVm5mkzMcS4WZvWFmS82s\nLMzb08xeNLM14XOPVojjITPbYGYr4uYljMMi08LxW25mxa0c1xQz+yAcs6VmdnLcsqtDXKvN7F9b\nMK59zWyema0ys5VmdkWYn9Fj1kBcGT1mZtbNzBaa2bIQ1w1h/gAzWxCO1xNm1iXM7xqmy8PyglaO\n6w9m9l7c8Roa5rfav/2wvRwzW2Jmz4Xp1j9e7t5hByAHeAcYCHQBlgGDMhhPBdC3zrxbgMlhfDJw\ncyvEcQxQDKxIFgdwMvACYMAIYEErxzUF+HmCsoPC37MrMCD8nXNaKK59gOIw3hN4O2w/o8esgbgy\neszCfvcI452BBeE4PAmMD/N/D0wK45cBvw/j44EnWuh41RfXH4BxCcq32r/9sL0rgceA58J0qx+v\njn6GMBwod/d33f1LYBYwNsMx1TUWeCSMPwKc3tIbdPf5wMcpxjEW+KNH/gfoY2b7tGJc9RkLzHL3\nL9z9PaCc6O/dEnGtd/fXw/gWYBXQnwwfswbiqk+rHLOw31vDZOcwOHA88FSYX/d4xY7jU8Bos/S/\nQbiBuOrTav/2zSwfOAV4IEwbGTheHT0h9Afej5uupOH/MC3Ngb+a2WIzmxjm/Yu7r4foPziwV4Zi\nqy+OtnAMLw+n7A/FNallJK5wej6M6NdlmzlmdeKCDB+z0PyxFNgAvEh0NrLJ3WsSbLs2rrB8M5DX\nGnG5e+x43RiO1x1mFntreGv+He8E/g+wM0znkYHj1dETQqKsmcnrbI9y92LgJOBHZnZMBmNJVaaP\n4b3AAcBQYD3wmzC/1eMysx7An4CfuPunDRVNMK/FYksQV8aPmbvvcPehQD7RWcihDWw7Y3GZWSFw\nNXAIcDiwJ3BVa8ZlZt8FNrj74vjZDWy7xeLq6AmhEtg3bjofWJehWHD3deFzA/A00X+Uj2KnoeFz\nQ4bCqy+OjB5Dd/8o/CfeCdzP100crRqXmXUm+tKd6e7/L8zO+DFLFFdbOWYhlk3AK0Rt8H3MLDfB\ntmvjCst7k3rTYXPjGhOa3tzdvwAepvWP11HAaWZWQdSsfTzRGUOrH6+OnhAWAQeF3vouRB0wszMR\niJl1N7OesXHgRGBFiOf8UOx84NlMxNdAHLOB88IVFyOAzbFmktZQp832DKJjFotrfLjiYgBwELCw\nhWIw4EFglbvfHrcoo8esvrgyfczMrJ+Z9QnjuwEnEPVvzAPGhWJ1j1fsOI4D5nroMW2FuN6KS+pG\n1E4ff7xa/O/o7le7e767FxB9R81191IycbzS1TvdVgeiKwXeJmrD/EUG4xhIdIXHMmBlLBaitr+X\ngTXhc89WiOVxoqaEr4h+bVxUXxxEp6d3h+P3BlDSynE9Gra7PPxH2Ceu/C9CXKuBk1owrpFEp+TL\ngaVhODnTx6yBuDJ6zIAiYEnY/grg+rj/AwuJOrP/L9A1zO8WpsvD8oGtHNfccLxWADP4+kqkVvu3\nHxfjsXx9lVGrHy89ukJERICO32QkIiIpUkIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERIL/\nDwTtrJ88dGhYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f626d32e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 11s 14ms/step\n",
      "Test accuracy: 0.003412109356140718\n",
      "Test loss: 0.004978430719929748\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
